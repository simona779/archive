Entrambi i concept si basano sulla provocazione, in quanto nel primo caso affidiamo alla macchina il sapere di capire chi siamo, inteso come individuo, e di inserirci in una caregoria ben precisa (possiamo risultare anche delle persone "fake"). Per aumentare la provocazione possiamo inserire delle categorie molto nette. Ma davvero possiamo chiedere ad una macchina chi siamo?? Molti ambiziosi potrebbero prenderla sul personale.
Il secondo si apre ad una sfera più ampia, in quanto, presupponendo che le macchine ci vedono, possono capire com'è fatta l'umanità. La sensazione che voglio che si ha quando si ha a che fare con questo secondo progetto è quella di inserire l'utente nella stessa concezione del "Grande Fratello", facendolo diventare esso stesso il "Dio" manipolatore. Ma non solo, anche la sensazione di ansia e curiosità nell'attendere il caricamento dell'occhio sul mondo. Non sappiamo cosa può capitare, e se può capitare lo stesso in più posti.


__Concept 1_WHO I AM?:__

___Analisi___

"Who i am?" è una domanda che spesso ci poniamo, da quando nasciamo e cresciamo ci portiamo sulle spalle il peso di questa frase, chi sono? 
Dato il periodo storico in cui viviamo, siamo sommersi da macchine che utilizziamo quotidianamente, a cui diamo molto di noi, molto spesso anche inconsapevolmente o inconsciamente. Possono loro aiutarci a rispondere a questa domanda?
Il progetto si basa sulla provocazione, dato che è complesso l'essere umano probabilmente la risposta a questa domanda potrebbe portare a strane conseguenze per l'individuo che la richiederebbe.

___What is?___

L'artefatto finale prende la forma di un sito. Un sito che comprende una barra di ricerca su cui verrà richiesto l'accesso di un determinato profilo social da cui si rivelerà la personalità della persona.

___How does it work?___

Tramite una serie di categorie ben precise l'algoritmo raccoglie le parole chiavi maggiormente utilizzate all'interno di un social (da decidere) del profilo della persona.
Le categorie su cui andrà racchiusa la personalità dell'utente sono distinte e composte da più parole così che si possa avere un quadro completo della persona.

___What does it mean?___

La provocazione di affidare ad una macchina una domanda così complessa, che racchiude una persona, ci porta a pensare ad una auto-analisi su noi stessi. Potremmo scoprire cose nuove? Ma sopratutto come ci vede lei? Ed è lo stesso che vedono le altre persone?

___What if?___

...

__Concept 2_THE BIG EYE:__

___Analisi___

"The big eye" è un progetto che, come quello precedente, pone delle domande ben precise alle macchine: può una macchina capire chi siamo come società? Come mondo globale?
Anche qui il termine chiave è provocazione, in quanto gioca su sensazioni ben precise che portano all'utente a porsi delle domande di auto-analisi. Una macchina può definirci come società? Ma sopratutto, può vederci per quello che siamo? 
Ci troviamo di fronte un progetto che vuole portare in superficie le tematiche di realtà/finzione, superiorità/nessuna possibilità di scelta.

___What is?___

L'artefatto finale si presenta come un sito che raccoglie, tramite le telecamere cosparse nel mondo, un'unica immagine della realtà, che non è quella dei social, ma appunto quella concreta, quella che c'è ma che non mostriamo quasi mai.
Il sito si presenterà con un'unica icona di refresh, in cui ogni volta che verrà cliccata, apparirà un'immagine diversa da quella precedente. L'immagine che carica, prenderà la forma di un mappamondo su cui saranno collocati i diversi video live delle telecamere inseriti nei posti reali all'interno della cartina. Questi saranno intersecati tramite un morphing per poter omogeneizzare l'immagine.
La provocazione sta nel cambiamento, noi cambiamo ogni volta che decidiamo di ricaricare l'immagine, e siamo solo noi a decidere quando. Noi non siamo artefici di ciò che guardiamo, ma consapevoli che stiamo guardando cose o persone inconsapevoli del nostro sguardo su di essi. Si hanno più livelli di senso che si contrappongono tra di loro. La sensazione di non sapere cosa aspettarsi da ciò che ci apparirà sullo schermo è quella che ci porta ad andare avanti nella ricerca (un pò come chatroulette).

___How does it work?___

L'algoritmo prende gli ID aperti delle telecamere e li randomizza nel momento di ricarica dell'immagine. Creerà un morphing tra i diversi video e li inserisce in uno spazio preciso. Dato che tutte le webcam riportano il nome del luogo, l'algoritmo lo inserisce all'interno della cartina.

___What does it mean?___

Il senso del progetto si racchiude su diversi livelli di comprensione. Il fatto che noi siamo liberi di cambiare quante volte vogliamo "l'occhio sul mondo" e che questo cambia a sua volta, ci fa rendere conto che definire in modo chiuso e limitato un'intera società è un impresa probabilmente impossibile. 

___What if?___

Come potrebbe essere spunto di ricerche? Come possiamo portarlo ad una ricerca di dati?
E se venisse inserita una memoria (limitata) sulla registrazione delle immagini per poter cercare l'identità del mondo in una data ben precisa?

_Reference generali:_

* http://128.111.69.4/~jevbratt/1_to_1/interface_iv/index.html  
* https://0100101110101101.org/no-fun/ 
* http://manovich.net/content/04-projects/150-instagram-and-contemporary-image/instagram_book_manovich.pdf 
* http://sureskumar.com/?cat=17 
* https://www.creativeapplications.net/news/ethical-machines-podcast/ 
* https://interaccess.org/exhibition/constructed-land 

___Concept definitivo___

![Imgur](https://i.imgur.com/S8vfPSa.png)

Parola chiave: momento, attimo. Cosa può succedere se ognuno di noi crea un’istantanea del mondo con l’aiuto delle telecamere?
In questo caso non si avrebbe più la provocazione come il grande fratello ma delle istantanee collegate in base all’attimo in cui viene effettuato il caricamento.
L’algoritmo dovrebbe ricavare, tramite il fuso orario di chi sta utilizzando il sito, randomicamente le telecamere cosparse nel mondo. L’immagine si compone man mano con l’utilizzo e a fine giornata si elimina, o finisce in un archivio. Il senso di chiedere alla macchina come vede il mondo rimane, e così potrebbe risultare interessante anche ciò che deriva dalla visualizzazione. 
Un’altra componente aggiuntiva è l’utilizzo della video classification del machine learning, così da poter capire la macchina come percepisce ciò che vede, ed inserirlo in una didascalia. 
La componente del fuso orario sarebbe il limite di ricerca delle telecamere in quanto l’algoritmo ricava gli elementi simili del posto in cui l’utente sta ricercando. In definitiva, tramite la luce, si compone una linea di immagini che hanno per somiglianza un intervallo di valori.

_Link utili per l'algoritmo_

* https://ml5js.org/docs/video-classification-example 
Ciò che vede la macchina per somiglianza.

* https://www.youtube.com/watch?v=WH31daSj4nc 
Come ricavare un video live.

* https://github.com/bitcraftlab/opencv-webcam-processing 
Opencv libreria.




